<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Siqi Zhang</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="bio.html">Biography</a></div>
<div class="menu-item"><a href="publication.html">Research</a></div>
<div class="menu-item"><a href="teaching.html">Teaching</a></div>
<div class="menu-category">Misc</div>
<div class="menu-item"><a href="links.html">Useful&nbsp;Links</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
<div id="subtitle"></div>
</div>
<h2>Publications (<a href="https://scholar.google.com/citations?user=0M171lEAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a>)</h2>
<p></p>
<dl>
<dt>Generalization Bounds of Nonconvex-(Strongly)-Concave Stochastic Minimax Optimization</dt>
<dd><p>
<b>Siqi Zhang*</b>, Yifan Hu*, Liang Zhang, Niao He. <br />
<i>International Conference on Artificial Intelligence and Statistics (AISTATS) 2024</i> 
<a href="https://arxiv.org/abs/2205.14278" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a> <a href="https://opt-ml.org/papers/2022/paper70.pdf" target=&ldquo;blank&rdquo;>&nbsp;[Workshop]</a> <a href="https://proceedings.mlr.press/v238/zhang24c.html" target=&ldquo;blank&rdquo;>&nbsp;[AISTATS]</a>

<br />
</p></dd>
<dt>Communication-Efficient Gradient Descent-Accent Methods for Distributed Variational Inequalities: Unified Analysis and Local Updates</dt>
<dd><p>
<b>Siqi Zhang*</b>, Sayantan Choudhury*, Sebastian U Stich, Nicolas Loizou. <br />
<i>International Conference on Learning Representations (ICLR) 2024</i>
<a href="https://arxiv.org/abs/2306.05100" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a> <a href="https://opt-ml.org/papers/2022/paper84.pdf" target=&ldquo;blank&rdquo;>&nbsp;[Workshop]</a> <a href="https://openreview.net/pdf?id=hORCalGn3Z" target=&ldquo;blank&rdquo;>&nbsp;[ICLR]</a>

<br />
</p></dd>
<dt>The Complexity of Nonconvex-Strongly-Concave Minimax Optimization</dt>
<dd><p>
<b>Siqi Zhang*</b>, Junchi Yang*, Cristobal Guzman, Negar Kiyavash and Niao He. <br />
<i>Uncertainty in Artificial Intelligence (UAI) 2021</i> 
<a href="https://arxiv.org/abs/2103.15888" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a> <a href="https://proceedings.mlr.press/v161/zhang21c.html" target=&ldquo;blank&rdquo;>&nbsp;[UAI]</a>

<br />
</p></dd>
<dt>Biased Stochastic First-Order Methods for Conditional Stochastic Optimization and Applications in Meta Learning</dt>
<dd><p>
Yifan Hu*, <b>Siqi Zhang*</b>, Xin Chen, Niao He. <br />
<i>Neural Information Processing Systems (NeurIPS) 2020</i> 
<a href="https://arxiv.org/abs/2002.10790" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a> <a href="https://proceedings.neurips.cc/paper/2020/hash/1cdf14d1e3699d61d237cf76ce1c2dca-Abstract.html" target=&ldquo;blank&rdquo;>&nbsp;[NeurIPS]</a>

<br />
</p></dd>
<dt>A Catalyst Framework for Minimax Optimization</dt>
<dd><p>
Junchi Yang, <b>Siqi Zhang</b>, Negar Kiyavash, Niao He. <br />
<i>Neural Information Processing Systems (NeurIPS) 2020</i> 
<a href="https://proceedings.neurips.cc/paper/2020/hash/3db54f5573cd617a0112d35dd1e6b1ef-Abstract.html" target=&ldquo;blank&rdquo;>&nbsp;[NeurIPS]</a>


<br /></p></dd>
<dt><b></b>(* denotes equal contributions)<b></b></dt>
<dd><p>
</p></dd>
</dl>
<h2>Other Publications</h2>
<p></p>
<dl>
<dt>Avoid Overclaims: Summary of Complexity Bounds for Algorithms in Minimization and Minimax Optimization</dt>
<dd><p>
<b>Siqi Zhang</b>, Yifan Hu. <br />
<i>International Conference on Learning Representations (ICLR) 2025 (Blogposts Track)</i>
<a href="https://iclr-blogposts.github.io/2025/blog/opt-summary/" target=&ldquo;blank&rdquo;>&nbsp;[ICLR Blogposts]</a> <a href="https://opt-eng-ana.github.io/blog/2025/opt-summary/" target=&ldquo;blank&rdquo;>&nbsp;[Keep Updated]</a>
</p></dd>
</dl>
<h2>Preprints</h2>
<p></p>
<dl>
<dt>First-Order Optimization Inspired from Finite-Time Convergent Flows</dt>
<dd><p>
<b>Siqi Zhang</b>, Mouhacine Benosman, Orlando Romero, Anoop Cherian. 2021 
<a href="https://arxiv.org/abs/2010.02990" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a>
</p></dd>
<dt>On the Convergence Rate of Stochastic Mirror Descent for Nonsmooth Nonconvex Optimization</dt>
<dd><p>
<b>Siqi Zhang</b>, Niao He. 2018 
<a href="https://arxiv.org/abs/1806.04781" target=&ldquo;blank&rdquo;>&nbsp;[arXiv]</a>
</p></dd>
</dl>
<h2>Selected Talks</h2>
<dl>
<dt><i>Generalization in Nonconvex Minimax Optimization: A Comprehensive Study</i></dt>
<dd><p>
INFORMS Optimization Society Conference, Houston, USA, 2024.03
<br />
CAMDA Conference, College Station, USA, 2023.05
</p></dd>
<dt><i>Communication-Efficient Federated Learning Algorithms for Variational Inequalities</i></dt>
<dd><p>
SIAM Conference on Optimization (OP23), Seattle, USA, 2023.06
<br />
Annual Conference on Information Sciences and Systems (CISS 2023), Baltimore, USA, 2023.03
</p></dd>
<dt><i>Nonconvex Minimax Optimization: Fundamental Limits, Efficient Algorithms and Generalization</i></dt>
<dd><p>
INFORMS Annual Meeting, Indianapolis, USA, 2022.10
<br />
MINDS & CIS Seminar, JHU, Baltimore, USA, 2022.10
<br />
International Conference on Continuous Optimization (ICCOPT), Bethlehem, USA, 2022.07

</p></dd>
</dl>
<div id="footer">
<div id="footer-text">
Page generated 2025-05-08, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
